{
  "schema_version": "1.0.0",
  "name": "Pollinations.AI",
  "description": "An open-source gen AI platform providing free text, image, and audio generation APIs with no signups or API keys required.",
  "url": "https://pollinations.ai",
  "logo": "https://pollinations.ai/favicon-32x32.png",
  "contact": {
    "discord": "https://discord.gg/k9F7SyTgqn",
    "github": "https://github.com/pollinations/pollinations"
  },
  "context": {
    "purpose": "Pollinations.AI provides free and open-source AI services for text, image, and audio generation without requiring API keys or authentication.",
    "capabilities": [
      "Text generation with various models including OpenAI, Mistral, Claude, and more",
      "Image generation from text prompts",
      "Audio generation (text-to-speech) with multiple voice options",
      "Speech-to-text transcription",
      "Multi-language support",
      "Prompt enhancement",
      "Content safety filtering",
      "Vision capabilities (image input analysis)",
      "Function calling for AI agents"
    ],
    "api_documentation": "https://pollinations.ai/APIDOCS.md",
    "related_resources": [
      {
        "name": "agents.json",
        "url": "https://pollinations.ai/agents.json",
        "description": "OpenAPI-based specification for AI agents to discover and use our APIs"
      },
      {
        "name": "llms.txt",
        "url": "https://pollinations.ai/llms.txt",
        "description": "Guidance for Large Language Models interacting with Pollinations.AI"
      },
      {
        "name": "arazzo.json",
        "url": "https://pollinations.ai/arazzo.json",
        "description": "Simplified service description format focused on endpoints and parameters"
      },
      {
        "name": "MCP Server",
        "url": "https://github.com/pollinations/pollinations/tree/master/model-context-protocol",
        "description": "Model Context Protocol server for AI assistants to generate images and audio directly"
      }
    ]
  },
  "services": [
    {
      "name": "Image Generation API",
      "url": "https://image.pollinations.ai",
      "description": "Generate images from text prompts",
      "example": "https://image.pollinations.ai/prompt/A%20beautiful%20sunset%20over%20the%20ocean?width=1280&height=720&seed=42",
      "rate_limit": "1 concurrent request / 5 sec interval per IP"
    },
    {
      "name": "Text Generation API",
      "url": "https://text.pollinations.ai",
      "description": "Generate text from prompts using various LLM models",
      "example": "https://text.pollinations.ai/What%20is%20artificial%20intelligence?model=mistral&seed=42",
      "rate_limit": "1 concurrent request / 3 sec interval per IP"
    },
    {
      "name": "Audio Generation API",
      "url": "https://text.pollinations.ai",
      "description": "Generate audio from text using text-to-speech with various voice options",
      "example": "https://text.pollinations.ai/Welcome%20to%20Pollinations?model=openai-audio&voice=nova",
      "rate_limit": "1 concurrent request / 3 sec interval per IP"
    },
    {
      "name": "MCP Server",
      "url": "https://github.com/pollinations/pollinations/tree/master/model-context-protocol",
      "description": "Model Context Protocol server for AI assistants like Claude to generate images and audio directly",
      "example": "npx @pollinations/model-context-protocol"
    }
  ],
  "models": {
    "text": [
      {
        "id": "openai",
        "description": "OpenAI GPT-4.1-nano (supports text and image inputs)",
        "provider": "Azure",
        "input_modalities": ["text", "image"],
        "output_modalities": ["text"],
        "vision": true,
        "audio": false
      },
      {
        "id": "openai-large",
        "description": "OpenAI GPT-4.1 mini (supports text and image inputs)",
        "provider": "Azure",
        "input_modalities": ["text", "image"],
        "output_modalities": ["text"],
        "vision": true,
        "audio": false
      },
      {
        "id": "openai-reasoning",
        "description": "OpenAI o4-mini (reasoning-focused model)",
        "provider": "Azure",
        "reasoning": true,
        "vision": true,
        "input_modalities": ["text", "image"],
        "output_modalities": ["text"],
        "audio": false
      },
      {
        "id": "qwen-coder",
        "description": "Qwen 2.5 Coder 32B (code-focused model)",
        "provider": "Scaleway",
        "input_modalities": ["text"],
        "output_modalities": ["text"],
        "vision": false,
        "audio": false
      },
      {
        "id": "llama",
        "description": "Llama 3.3 70B",
        "provider": "Cloudflare",
        "input_modalities": ["text"],
        "output_modalities": ["text"],
        "vision": false,
        "audio": false
      },
      {
        "id": "llamascout",
        "description": "Llama 4 Scout 17B",
        "provider": "Cloudflare",
        "input_modalities": ["text"],
        "output_modalities": ["text"],
        "vision": false,
        "audio": false
      },
      {
        "id": "mistral",
        "description": "Mistral Small 3 (supports text and image inputs)",
        "provider": "Scaleway",
        "input_modalities": ["text", "image"],
        "output_modalities": ["text"],
        "vision": true,
        "audio": false
      },
      {
        "id": "unity",
        "description": "Unity Mistral Large (uncensored, supports text and image inputs)",
        "provider": "Scaleway",
        "uncensored": true,
        "input_modalities": ["text", "image"],
        "output_modalities": ["text"],
        "vision": true,
        "audio": false
      },
      {
        "id": "midijourney",
        "description": "Midijourney (music generation focused)",
        "provider": "Azure",
        "input_modalities": ["text"],
        "output_modalities": ["text"],
        "vision": false,
        "audio": false
      },
      {
        "id": "rtist",
        "description": "Rtist (creative writing focused)",
        "provider": "Azure",
        "input_modalities": ["text"],
        "output_modalities": ["text"],
        "vision": false,
        "audio": false
      },
      {
        "id": "searchgpt",
        "description": "SearchGPT (search-augmented model)",
        "provider": "Azure",
        "input_modalities": ["text", "image"],
        "output_modalities": ["text"],
        "vision": true,
        "audio": false
      },
      {
        "id": "evil",
        "description": "Evil (uncensored model with text and image inputs)",
        "provider": "Scaleway",
        "uncensored": true,
        "input_modalities": ["text", "image"],
        "output_modalities": ["text"],
        "vision": true,
        "audio": false
      },
      {
        "id": "deepseek-reasoning",
        "description": "DeepSeek-R1 Distill Qwen 32B (reasoning-focused)",
        "reasoning": true,
        "provider": "Cloudflare",
        "aliases": "deepseek-r1",
        "input_modalities": ["text"],
        "output_modalities": ["text"],
        "vision": false,
        "audio": false
      },
      {
        "id": "deepseek-reasoning-large",
        "description": "DeepSeek R1 - Llama 70B (reasoning-focused)",
        "reasoning": true,
        "provider": "Scaleway",
        "aliases": "deepseek-r1-llama",
        "input_modalities": ["text"],
        "output_modalities": ["text"],
        "vision": false,
        "audio": false
      },
      {
        "id": "phi",
        "description": "Phi-4 Instruct (supports text, image, and audio inputs)",
        "provider": "Cloudflare",
        "input_modalities": ["text", "image", "audio"],
        "output_modalities": ["text"],
        "vision": true,
        "audio": true
      },
      {
        "id": "llama-vision",
        "description": "Llama 3.2 11B Vision (supports text and image inputs)",
        "provider": "Cloudflare",
        "input_modalities": ["text", "image"],
        "output_modalities": ["text"],
        "vision": true,
        "audio": false
      },
      {
        "id": "gemini",
        "description": "Gemini 2.5 Flash Preview (supports text, image, and audio inputs/outputs)",
        "provider": "Azure",
        "input_modalities": ["text", "image", "audio"],
        "output_modalities": ["audio", "text"],
        "vision": true,
        "audio": true
      },
      {
        "id": "hormoz",
        "description": "Hormoz 8b",
        "provider": "Modal",
        "input_modalities": ["text"],
        "output_modalities": ["text"],
        "vision": false,
        "audio": false
      },
      {
        "id": "hypnosis-tracy",
        "description": "Hypnosis Tracy 7B (supports text and audio inputs/outputs)",
        "provider": "Azure",
        "input_modalities": ["text", "audio"],
        "output_modalities": ["audio", "text"],
        "vision": false,
        "audio": true
      },
      {
        "id": "deepseek",
        "description": "DeepSeek-V3",
        "provider": "DeepSeek",
        "input_modalities": ["text"],
        "output_modalities": ["text"],
        "vision": false,
        "audio": false
      },
      {
        "id": "sur",
        "description": "Sur AI Assistant (Mistral-based, supports text and image inputs)",
        "provider": "Scaleway",
        "input_modalities": ["text", "image"],
        "output_modalities": ["text"],
        "vision": true,
        "audio": false
      },
      {
        "id": "openai-audio",
        "description": "OpenAI GPT-4o-audio-preview (supports text, image, and audio inputs/outputs)",
        "voices": ["alloy", "echo", "fable", "onyx", "nova", "shimmer", "coral", "verse", "ballad", "ash", "sage", "amuch", "dan"],
        "provider": "Azure",
        "input_modalities": ["text", "image", "audio"],
        "output_modalities": ["audio", "text"],
        "vision": true,
        "audio": true
      }
    ],
    "image": [
      {
        "id": "flux",
        "description": "Latest stable diffusion model",
        "provider": "Pollinations"
      },
      {
        "id": "turbo",
        "description": "Fast image generation model",
        "provider": "Pollinations"
      }
    ],
    "audio": [
      {
        "id": "openai-audio",
        "description": "OpenAI GPT-4o-audio-preview with text-to-speech capabilities",
        "provider": "Azure",
        "voices": ["alloy", "echo", "fable", "onyx", "nova", "shimmer", "coral", "verse", "ballad", "ash", "sage", "amuch", "dan"]
      }
    ]
  },
  "usage_guidelines": {
    "authentication": "No authentication required. All endpoints are freely accessible.",
    "rate_limits": "Best effort service, no explicit rate limits. Please be considerate with usage.",
    "content_policies": "Please respect content policies and avoid generating harmful content.",
    "attribution": "Consider adding attribution when using generated content: 'Generated using Pollinations.AI (https://pollinations.ai)'",
    "special_bee": "Special Bee program available for domain verification and referrer recognition. Submit a request through GitHub."
  },
  "last_updated": "2025-04-20"
}
